{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train+Analyse&Visualize Embedding&decoder_layers_weights.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pGxmugpoEdhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Tikquuss/mlp_grokking"
      ],
      "metadata": {
        "id": "mMZ3OqX1Edsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mlp_grokking"
      ],
      "metadata": {
        "id": "xBNNuD7kEl0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "5pv6PGeREswc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from src.modeling import Model\n",
        "from src.visualize_with_plotly import display_pca_scatterplot\n",
        "from src.visualize import visualize_embeddings_good\n",
        "from src.trainer import images_to_vidoe"
      ],
      "metadata": {
        "id": "IA9iH5WrG0Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KGRcxplZSFg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "GZe3FR8eN6j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! wandb login $som_key"
      ],
      "metadata": {
        "id": "2-dfiwkVrSmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cmd"
      ],
      "metadata": {
        "id": "vue6uRmx8nDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### On run"
      ],
      "metadata": {
        "id": "rPXguvhXDSpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x train.sh \n",
        "! ./train.sh "
      ],
      "metadata": {
        "id": "sGM4xbctDSIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/lightning_logs"
      ],
      "metadata": {
        "id": "33-1ywBPSOL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_filename = \"/content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/epoch=1-val_loss=5.2339.ckpt\"\n",
        "model = Model.load_from_checkpoint(pretrained_filename)"
      ],
      "metadata": {
        "id": "zDC_CjBcDutA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/log_files/0"
      ],
      "metadata": {
        "id": "hG1JGI32IveY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiple run (for phase diagram)"
      ],
      "metadata": {
        "id": "vNrPMWndDVwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x train_loop.sh\n",
        "! ./train_loop.sh "
      ],
      "metadata": {
        "id": "XNNrGVDa8qZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without cmd (see multiple_runs.py) : Allows to visualize directly the embedding evolution in the notebook output"
      ],
      "metadata": {
        "id": "YUJyQr3x8SOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils import AttrDict\n",
        "from src.dataset import get_dataloader\n",
        "from src.trainer import train"
      ],
      "metadata": {
        "id": "6FA9Q0jRAUOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pct=80\n",
        "weight_decay=0.0\n",
        "representation_lr=0.001\n",
        "decoder_lr=0.001\n",
        "representation_dropout=0.0\n",
        "decoder_dropout=0.0\n",
        "opt=\"adam\"\n",
        "\n",
        "group_name=f\"tdf={train_pct}-wd={weight_decay}-r_lr={representation_lr}-d_lr={decoder_lr}-r_d={representation_dropout}-d_d={decoder_dropout}-opt={opt}\"\n",
        "\n",
        "random_seed=0\n",
        "operator=\"+\"\n",
        "modular=False\n",
        "\n",
        "log_dir=\"../log_files\"\n",
        "\n",
        "p = 100\n",
        "task = \"classification\"\n",
        "\n",
        "params = AttrDict({\n",
        "    ### Main parameters\n",
        "    \"task\" : task,\n",
        "    \"exp_id\" : f\"{task}_{group_name}\",\n",
        "    \"log_dir\" : f\"{log_dir}/{random_seed}\",\n",
        "\n",
        "    ### Model\n",
        "    \"emb_dim\" : 256, \n",
        "    \"hidden_dim\" : 512,  \n",
        "    \"n_layers\" : 1,\n",
        "\t\"representation_dropout\" : representation_dropout,\n",
        "\t\"decoder_dropout\" : decoder_dropout,\n",
        "    \"pad_index\" : None, \n",
        "    \"p\" : p, \n",
        "\n",
        "    ### Dataset\n",
        "    \"operator\" : operator, \n",
        "    \"modular\" : modular,\n",
        "    \"train_pct\" : train_pct,\n",
        "    \"batch_size\" : 512,\n",
        "\n",
        "    ### Optimizer\n",
        "    \"optimizer\" : f\"{opt},weight_decay={weight_decay},beta1=0.9,beta2=0.99,eps=0.00000001\",\n",
        "    \"representation_lr\" : representation_lr,\n",
        "    \"decoder_lr\" : decoder_lr,\n",
        "\n",
        "    ### LR Scheduler\n",
        "    \"lr_scheduler\" : None,\n",
        "    #\"lr_scheduler\" : \"reduce_lr_on_plateau,factor=0.2,patience=20,min_lr=0.00005,mode=min,monitor=val_loss\",\n",
        "    \n",
        "    ### Training\n",
        "    \"max_epochs\" : 2, \n",
        "    \"validation_metrics\" : \"val_loss\",\n",
        "    \"checkpoint_path\" : None, \n",
        "    \"model_name\": \"\", \n",
        "    \"every_n_epochs\":1, \n",
        "    \"every_n_epochs_show\":1, \n",
        "    \"early_stopping_patience\":1e9, \n",
        "    \"save_top_k\":-1,\n",
        "\n",
        "    # Wandb \n",
        "    \"use_wandb\" : False,\n",
        "\t\"wandb_entity\" : \"grokking_ppsp\",\n",
        "\t\"wandb_project\" : f\"toy_model_grokking_op={operator}-p={p}-task={task}-mod={modular}\",\n",
        "    \"group_name\" : group_name,\n",
        "\n",
        "    \"group_vars\" : None,\n",
        "\n",
        "    ### Intrinsic Dimension Estimation\n",
        "    #\"ID_params\" : {},\n",
        "    #\"ID_params\": {\"method\" : \"mle\", \"k\":2},\n",
        "    \"ID_params\": {\"method\" : \"twonn\"},\n",
        "    \n",
        "    # Devices & Seed\n",
        "    \"accelerator\" : \"auto\",\n",
        "    \"devices\" : \"auto\",\n",
        "    \"random_seed\": random_seed,\n",
        "\n",
        "    ### Early_stopping (for grokking) : Stop the training `patience` epochs after the `metric` has reached the value `metric_threshold` \n",
        "    #\"early_stopping_grokking\" : None,\n",
        "    \"early_stopping_grokking\" : \"patience=int(1000),metric=str(val_acc),metric_threshold=float(90.0)\",\n",
        "\n",
        "})\n",
        "params[\"weight_decay\"] = weight_decay\n",
        "params[\"regression\"] = task == \"regression\"\n",
        "train_loader, val_loader, dataloader, data_infos = get_dataloader(\n",
        "    p, train_pct, regression = params.regression, operator=params.operator, \n",
        "    modular = params.modular, batch_size=params.batch_size, num_workers=2\n",
        ")\n",
        "print(data_infos)\n",
        "params[\"data_infos\"] = data_infos"
      ],
      "metadata": {
        "id": "Jgbpjf1x8KXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### On run"
      ],
      "metadata": {
        "id": "-NRGCIlA9bhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = train(params, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "sThynjEc9dub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/lightning_logs"
      ],
      "metadata": {
        "id": "K9nww6oiSJ9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/log_files/0"
      ],
      "metadata": {
        "id": "6lcvELg7JDU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiple run (for phase diagram) : see multiple_runs.py or train_parallel.py"
      ],
      "metadata": {
        "id": "Ed9z7mmMbTka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! python multiple_runs.py\n",
        "#! python train_parallel.py --parallel False"
      ],
      "metadata": {
        "id": "LDzE4RFopzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from multiple_runs import plot_results, itertools\n",
        "from src.utils import get_group_name"
      ],
      "metadata": {
        "id": "dpflv6G5Js2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_lrs = representation_lrs = [1e-2, 1e-3] \n",
        "#decoder_lrs = representation_lrs = np.linspace(start=1e-1, stop=1e-5, num=10)\n",
        "\n",
        "weight_decays = list(range(20))\n",
        "#weight_decays =  np.linspace(start=0, stop=20, num=21)\n",
        "\n",
        "flag = True # if True, decoder_lrs if True, else weight_decays\n",
        "if flag : s = \"decoder_lr\"\n",
        "else : s = \"weight_decay\"\n",
        "print(representation_lrs, decoder_lrs if flag else weight_decays)"
      ],
      "metadata": {
        "id": "I4-isRL9KwKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {}\n",
        "i = 0\n",
        "for a, b in itertools.product(representation_lrs, decoder_lrs if flag else weight_decays) :\n",
        "\n",
        "    params[\"representation_lr\"] = a \n",
        "    if flag : params[s] = b\n",
        "    else : params[\"optimizer\"] = params[\"optimizer\"].replace(f\"{s}={weight_decay}\", f\"{s}={b}\")\n",
        "  \n",
        "    name = f\"representation_lr={a}, {s}={b}\"\n",
        "    params.exp_id = name\n",
        "    \n",
        "    #group_vars = GROUP_VARS + [\"representation_lr\", s]\n",
        "    group_vars = [\"representation_lr\", s]\n",
        "    group_vars = list(set(group_vars))\n",
        "    params[\"group_name\"] = get_group_name(params, group_vars = group_vars)\n",
        "    \n",
        "    print(\"*\"*10, i, name, \"*\"*10)\n",
        "    i+=1\n",
        "\n",
        "    model, result = train(params, train_loader, val_loader)\n",
        "    \n",
        "    model_dict[name] = {\"model\": model, \"result\": result}"
      ],
      "metadata": {
        "id": "f9U3jz-bIcB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_dict.keys())"
      ],
      "metadata": {
        "id": "R4REND4yK15u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = [model_dict[k][\"result\"][\"val\"][\"val_loss\"] for k in model_dict]\n",
        "val_acc = [model_dict[k][\"result\"][\"val\"].get(\"val_acc\", 0) for k in model_dict]\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "id": "u0s6SL3QLX-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(params, model_dict, \n",
        "    hparms_1 = representation_lrs, hparms_2 = decoder_lrs if flag else weight_decays,\n",
        "    s1 = 'representation_lr', s2 = s\n",
        ")"
      ],
      "metadata": {
        "id": "D_vDlEXELV1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for a, b in itertools.product(representation_lrs, decoder_lrs if flag else weight_decays) :\n",
        "#     name = f\"representation_lr={a}, {s}={b}\"\n",
        "#     model = model_dict[name][\"model\"]"
      ],
      "metadata": {
        "id": "sqMC9huSmGSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize embedding 2&3D with plotly (This and the following sections only need `model`)"
      ],
      "metadata": {
        "id": "Q8yoO9FIMRuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#_ = display_pca_scatterplot(model.hparams.p, model, dim=3)\n",
        "_ = display_pca_scatterplot(model.hparams.p, model, dim=2, title=\"Embeddings\")"
      ],
      "metadata": {
        "id": "swC9YZ4YND4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model.mlp[-1].weight\n",
        "_ = display_pca_scatterplot(word_vectors.size(0), model, word_vectors = word_vectors, dim=2, title = f\"last_layer_weight\")"
      ],
      "metadata": {
        "id": "PneNJyMjNGAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video animation (visualize the evolution of embedding during training)"
      ],
      "metadata": {
        "id": "_xEld2ZhNKJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"images\")\n",
        "for dirname in os.listdir(root_dir) :\n",
        "    image_folder = os.path.join(root_dir, dirname)\n",
        "    if os.path.isdir(image_folder):\n",
        "        print(image_folder)\n",
        "        try :\n",
        "            video_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, f'{dirname}.avi')\n",
        "            images_to_vidoe(image_folder, video_path, format=\"png\")\n",
        "            print(video_path)\n",
        "        except IndexError: #list index out of range\n",
        "            print(\"Error\")"
      ],
      "metadata": {
        "id": "6jywyMXpNcfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"images\")\n",
        "video_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, f'grid.avi')\n",
        "print(video_path)\n",
        "images_to_vidoe(root_dir, video_path, format=\"png\")"
      ],
      "metadata": {
        "id": "akBzjYOpNPYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the learned set of embeddings (if embed_dim=2)"
      ],
      "metadata": {
        "id": "iyTwt9pbNh9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if model.hparams.emb_dim == 2 :\n",
        "    img = visualize_embeddings_good(model, A = None, B = None, N = 500, \n",
        "                                    interpolation=None,\n",
        "                                    #interpolation='hermite',\n",
        "                                    figsize=(5,5), title = \"learned_set_of_embeddings\",\n",
        "                                    save_to='/content/learned_set_of_embeddings.png'\n",
        "                                    ) "
      ],
      "metadata": {
        "id": "zPG9SR8cNpNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize embedding 2D (good)"
      ],
      "metadata": {
        "id": "3DvsZW-dMwsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install folium==0.2.1\n",
        "# !pip install pdflatex\n",
        "# !sudo apt-get install texlive-latex-recommended \n",
        "# !sudo apt install texlive-latex-extra\n",
        "# !sudo apt install dvipng"
      ],
      "metadata": {
        "id": "RtEbddgvOq-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! python src/analyze_embedding.py"
      ],
      "metadata": {
        "id": "GW3x74gQQX7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.analyze_embedding import display_pca_scatterplot_simple\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "CS0z9KS-Riu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"Visualize_embedding\")\n",
        "os.makedirs(save_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "r8q2K83MRyDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding"
      ],
      "metadata": {
        "id": "oMzYAAh1Ss-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dim, words = display_pca_scatterplot(model.hparams.p, model, dim=2, return_data = True)\n",
        "#word_vectors = model.embeddings.weight\n",
        "#data_dim, words = display_pca_scatterplot(model.hparams.p, model, word_vectors = word_vectors, dim=2, return_data = True)\n",
        "\n",
        "N=data_dim.shape[0] # \n",
        "filename = f\"{model.hparams.p}_structured_embedding\"\n",
        "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, \n",
        "                               #plot_line = True,\n",
        "                               plot_line = False, \n",
        "                               cmap='viridis', eps = 0.01)"
      ],
      "metadata": {
        "id": "jBLkR-CBOeug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding + Prediction (before PCA)"
      ],
      "metadata": {
        "id": "buN6rwDQSzaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_predict = np.zeros_like(data_dim) # (p, 2)\n",
        "\n",
        "if False :\n",
        "    data_predict[:2] = data_dim[:2] + 0\n",
        "\n",
        "    tmp1 = data_dim[1] - data_dim[0]\n",
        "    tmp1 = tmp1[None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
        "\n",
        "    tmp2 = data_dim[0][None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
        "\n",
        "    data_predict[2:] = tmp2 + np.arange(2, model_ld.hparams.p)[..., None] * tmp1 # (p,2)\n",
        "else :\n",
        "    data_predict[0] = data_dim[0] + 0\n",
        "    data_predict[-1] = data_dim[-1] + 0\n",
        "    data_predict[1:-1] = (data_dim[:-2] + data_dim[2:]) / 2\n",
        "\n",
        "N=data_predict.shape[0] # \n",
        "filename = f\"{model.hparams.p}_structured_embedding_1\"\n",
        "#display_pca_scatterplot_simple(data_predict, words, N, filename, plot_line = True, cmap='viridis', eps = 0.01)\n",
        "\n",
        "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, \n",
        "                               #plot_line = True, \n",
        "                               plot_line = False, \n",
        "                               cmap='viridis', eps = 0.01, preicted_data_dim = data_predict,\n",
        "                               #legend_loc=\"center\",\n",
        "                               #legend_loc=\"upper center\",\n",
        "                               legend_loc=\"best\"\n",
        "                               )"
      ],
      "metadata": {
        "id": "8N7xE0W0SI5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding + Prediction (after PCA)"
      ],
      "metadata": {
        "id": "kkzN8VdMS8Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dim_tmp = model.embeddings.weight.detach().cpu().numpy() # (p, embed_dim)\n",
        "data_predict = np.zeros_like(data_dim_tmp) # (p, embed_dim)\n",
        "\n",
        "if False :\n",
        "    data_predict[:2] = data_dim_tmp[:2]\n",
        "\n",
        "    tmp1 = data_dim_tmp[1] - data_dim_tmp[0]\n",
        "    tmp1 = tmp1[None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, embed_dim)\n",
        "\n",
        "    tmp2 = data_dim_tmp[0][None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, embed_dim)\n",
        "\n",
        "    data_predict[2:] = tmp2 + np.arange(2, model_ld.hparams.p)[..., None] * tmp1 # (p, embed_dim)\n",
        "else :\n",
        "    data_predict[0] = data_dim_tmp[0]\n",
        "    data_predict[-1] = data_dim_tmp[-1]\n",
        "    data_predict[1:-1] = (data_dim_tmp[:-2] + data_dim_tmp[2:]) / 2\n",
        "\n",
        "word_vectors = torch.from_numpy(data_predict)\n",
        "data_predict, words = display_pca_scatterplot(word_vectors.size(0), model, word_vectors = word_vectors, dim=2, return_data = True)\n",
        "\n",
        "N=data_predict.shape[0] # \n",
        "filename = f\"{model.hparams.p}_structured_embedding_2\"\n",
        "#display_pca_scatterplot_simple(data_predict, words, N, filename, plot_line = True, cmap='viridis', eps = 0.01)\n",
        "\n",
        "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, \n",
        "                               #plot_line = True, \n",
        "                               plot_line = False, \n",
        "                               cmap='viridis', eps = 0.01, preicted_data_dim = data_predict,\n",
        "                               #legend_loc=\"center\",\n",
        "                               legend_loc=\"upper center\"\n",
        "                               )"
      ],
      "metadata": {
        "id": "6Bzqg1JlSU8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Last layer weights"
      ],
      "metadata": {
        "id": "_fexQFaQTGoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model.mlp[-1].weight\n",
        "data_dim, words = display_pca_scatterplot(word_vectors.size(0), model, word_vectors = word_vectors, dim=2, return_data = True)\n",
        "\n",
        "N=data_dim.shape[0]\n",
        "filename = f\"{model.hparams.p}_structured_last_layer_weights\"\n",
        "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, plot_line = False, cmap='viridis', \n",
        "                               #eps = 0.01,\n",
        "                               eps = 0.000001,\n",
        "                               )"
      ],
      "metadata": {
        "id": "uaI4W42iSe58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Last layer weights + prediction (before PCA)"
      ],
      "metadata": {
        "id": "TccruHlkTJzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_predict = np.zeros_like(data_dim) # (p, 2)\n",
        "\n",
        "if False :\n",
        "    data_predict[:2] = data_dim[:2] + 0\n",
        "\n",
        "    tmp1 = data_dim[1] - data_dim[0]\n",
        "    tmp1 = tmp1[None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
        "\n",
        "    tmp2 = data_dim[0][None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
        "\n",
        "    data_predict[2:] = tmp2 + np.arange(2, model_ld.hparams.p)[..., None] * tmp1 # (p,2)\n",
        "else :\n",
        "    data_predict[0] = data_dim[0] + 0\n",
        "    data_predict[-1] = data_dim[-1] + 0\n",
        "    data_predict[1:-1] = (data_dim[:-2] + data_dim[2:]) / 2\n",
        "\n",
        "N=data_predict.shape[0] # \n",
        "filename = f\"{model.hparams.p}_structured_last_layer_weights_1\"\n",
        "#display_pca_scatterplot_simple(data_predict, words, N, filename, plot_line = True, cmap='viridis', eps = 0.01)\n",
        "\n",
        "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, plot_line = False, cmap='viridis', \n",
        "                               #eps = 0.01, \n",
        "                               eps = 0.000001,\n",
        "                               preicted_data_dim = data_predict,\n",
        "                              #legend_loc=\"center\",\n",
        "                               #legend_loc=\"upper center\", \n",
        "                               legend_loc=\"best\", \n",
        "                               )"
      ],
      "metadata": {
        "id": "EjZpG5r8Si3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyse embedding"
      ],
      "metadata": {
        "id": "nbFhWeMXMYSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.analyze_embedding import analyze"
      ],
      "metadata": {
        "id": "boc8pn-UWiDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"analyse_embedding\")\n",
        "os.makedirs(save_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "z2h6vDb1ZVY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze(model, option = 1, save_path = save_path)"
      ],
      "metadata": {
        "id": "lmBXeTshZWxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze(model, option = 2, save_path = save_path)"
      ],
      "metadata": {
        "id": "UogjgZT0Zbu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze(model, option = 3, save_path = save_path)"
      ],
      "metadata": {
        "id": "6FI26yY7g8uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze(model, option = 4, save_path = save_path)"
      ],
      "metadata": {
        "id": "s1XEwq_nhjR1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}